# Project
project:
  run_name:     HIT_24DOF
  restart_dir:  trained_model
  random_seed:  124
  log_interval: 1

# All parameters for setting up the environment
environment:
  env_name: hit
  num_procs_per_environment:  1
  num_parallel_environments:  2
  executable_path: ../../../flexi-extensions/build/bin/flexi
  parameter_file: ./simulation_files/parameter_flexi_eval.ini
  env_launcher: local

# All parameters for setting up the reward
reward:
  reward_kmin: 1
  reward_kmax: 9
  reward_scale: 0.4
  reward_spectrum_file: ./simulation_files/DNS_spectrum_stats_t2_to_t10.csv

# All parameters regarding the training
training:
  train_num_epochs: 5
  train_learning_rate: 1.e-4
  train_num_iterations: 0
  train_buffer_capacity: 2000
  train_files:
    - ./simulation_files/run_f200_N5_4Elems_State_0000003.000000000.h5
    - ./simulation_files/run_f200_N5_4Elems_State_0000004.000000000.h5
    - ./simulation_files/run_f200_N5_4Elems_State_0000005.000000000.h5
    - ./simulation_files/run_f200_N5_4Elems_State_0000006.000000000.h5

# All parameters for the agent
agent:
  actor_type: cnn_actor
  critic_type: cnn_critic
  dist_type: normal
  action_std: 0.02
  discount_factor: 0.995
  entropy_regularization: 0.0
  importance_ratio_clipping: 0.2

# Checkpointing
checkpoint:
  ckpt_interval: 10
  ckpt_num:      1000

# Evaluation
evaluation:
  eval_num_episodes:  1
  eval_interval:     10
  eval_files:
    - ./simulation_files/run_f200_N5_4Elems_State_0000008.000000000.h5

# SmartSim
smartsim:
  smartsim_port: 6780
  smartsim_network_interface: local
  smartsim_orchestrator: auto
