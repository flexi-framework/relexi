# YAML File

# Project
project:
  run_name:     32DOF_16runs_kmin1_kmax12
  restart_dir:  null
  random_seed:  124
  log_interval: 1

# All parameters for setting up the environment
environment:
  num_procs_per_environment:  1
  num_parallel_environments:  2
  executable_path: ../../../flexi-extensions/build/bin/flexi
  parameter_file: ./simulation_files/parameter_flexi.ini
  mesh_file: ./simulation_files/CART_HEX_PERIODIC_004_mesh.h5
  #local_dir: /var/tmp
  mpi_launch_mpmd: False
  env_launcher: local

# All parameters for setting up the reward
reward:
  reward_kmin: 1
  reward_kmax: 12
  reward_scale: 0.2
  reward_spectrum_file: ./simulation_files/DNS_spectrum_stats_t2_to_t10.csv

# All parameters regarding the training
training:
  train_num_epochs: 5
  train_learning_rate: 1.e-4
  train_num_iterations: 5
  train_buffer_capacity: 2000
  train_files:
    - ./simulation_files/run_f200_N7_4Elems_State_0000003.000000000.h5
    - ./simulation_files/run_f200_N7_4Elems_State_0000004.000000000.h5
    - ./simulation_files/run_f200_N7_4Elems_State_0000005.000000000.h5
    - ./simulation_files/run_f200_N7_4Elems_State_0000006.000000000.h5

# All parameters for the agent
agent:
  action_std: 0.02
  discount_factor: 0.995
  entropy_regularization: 0.0
  importance_ratio_clipping: 0.2

# Checkpointing
checkpoint:
  ckpt_interval: 10
  ckpt_num:      1000

# Evaluation
evaluation:
  eval_num_episodes: 1
  eval_interval:     5
  eval_files:
    - ./simulation_files/run_f200_N7_4Elems_State_0000008.000000000.h5

# Performance
performance:
  use_XLA:    False
  do_profile: False

# SmartSim
smartsim:
  smartsim_port: 6780
  smartsim_num_dbs: 1
  smartsim_launcher: pbs
  smartsim_orchestrator: pbs
