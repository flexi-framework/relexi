# YAML File

# Project
project:
  run_name:     Channel_Re180_Ma0p3
  restart_dir:  null
  random_seed:  124
  log_interval: 1

# All parameters for setting up the environment
environment:
  env_name: 'channel'
  num_procs_per_environment:  4
  num_parallel_environments:  1
  executable_path: ../../../flexi/flexi_dev/build_channel/bin/flexi
  parameter_file: ./simulation_files/Re180_Ma0.3/parameter_flexi.ini
  env_launcher: mpirun

# All parameters for setting up the reward
reward:
  reward_kmin: 1
  reward_kmax: 9
  reward_scale: 0.4
  reward_spectrum_file: ./simulation_files/LM_Channel_0180_mean_vel_fluc_prof.dat

# All parameters regarding the training
training:
  train_num_epochs: 5
  train_learning_rate: 1.e-4
  train_num_iterations: 1
  train_buffer_capacity: 2000
  train_files:
    - ./simulation_files/Re180_Ma0.3/Re180_turbulentChannel_Ma0p3_State_0000011.000000000.h5
    - ./simulation_files/Re180_Ma0.3/Re180_turbulentChannel_Ma0p3_State_0000012.000000000.h5
    - ./simulation_files/Re180_Ma0.3/Re180_turbulentChannel_Ma0p3_State_0000013.000000000.h5

# All parameters for the agent
agent:
  action_std: 0.02
  dist_type: beta
  discount_factor: 0.995
  entropy_regularization: 0.0
  importance_ratio_clipping: 0.2

# Checkpointing
checkpoint:
  ckpt_interval: 10
  ckpt_num:      1000

# Evaluation
evaluation:
  eval_num_episodes: 1
  eval_interval:     5
  eval_files:
    - ./simulation_files/Re180_Ma0.3/Re180_turbulentChannel_Ma0p3_State_0000015.000000000.h5

# Performance
performance:
  use_XLA:    False
  do_profile: False

# SmartSim
smartsim:
  smartsim_port: 6780
  smartsim_network_interface: local
  smartsim_orchestrator: auto
